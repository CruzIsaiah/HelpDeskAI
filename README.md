# HelpDesk AI â€“ Cloud-Deployed Voice Support Agent

HelpDesk AI is a voice-powered troubleshooting assistant that allows users to **speak their technical issue** and instantly receive **AI-generated step-by-step solutions**.  
The system uses Whisper for transcription, a RAG pipeline for knowledge retrieval, and an LLM for generating clear troubleshooting instructions.  
It is fully cloud-deployable and will be hosted on **AWS** for production.

---

## ğŸš€ Features

- ğŸ¤ **Voice Input** â€“ Users describe their problem via microphone
- ğŸ§  **Whisper Transcription** â€“ Converts speech to text
- ğŸ” **Entity Extraction** â€“ Finds devices, error codes, keywords
- ğŸ“š **RAG Pipeline** â€“ Retrieves relevant solutions from the knowledge base (Pinecone)
- ğŸ¤– **LLM Troubleshooting** â€“ Generates interactive step-by-step instructions
- ğŸ“ **Instruction Manual** â€“ Auto-generated PDF/Markdown for reuse
- ğŸ’¾ **Persistent Sessions** â€“ All interactions saved to PostgreSQL
- â˜ï¸ **AWS Deployment** â€“ Backend hosted on AWS (EC2 or Cloud Run equivalent)

---

## ğŸ§© Architecture Overview

```
User â†’ Microphone â†’ Whisper (STT)
       â†“
Transcript â†’ NLP Extraction â†’ Vector Search (Pinecone)
       â†“
LLM Reasoning â†’ Troubleshooting Steps â†’ Instruction Manual
       â†“
Frontend UI (React/Next.js)
```

**Backend:** FastAPI (Python)  
**Frontend:** React / Next.js  
**Database:** PostgreSQL  
**Vector DB:** Pinecone  
**Storage (Prod):** AWS S3  
**Hosting:** AWS EC2 / Elastic Beanstalk / Cloud Run  
**AI Models:** Whisper + OpenAI GPT (or model of choice)

---

## ğŸ“ Project Structure

```
HelpDeskAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # API routes: transcribe, troubleshoot
â”‚   â”‚   â”œâ”€â”€ db/                # Database models + session storage
â”‚   â”‚   â”œâ”€â”€ rag/               # RAG pipeline: embed, search, reason
â”‚   â”‚   â”œâ”€â”€ services/          # Whisper, manual generation
â”‚   â”‚   â””â”€â”€ utils/             # Helper functions
â”‚   â”œâ”€â”€ docs/manuals/          # Knowledge base documents
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ run.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/components/
â”‚   â”œâ”€â”€ src/pages/
â”‚   â”œâ”€â”€ package.json
â”‚
â””â”€â”€ docker-compose.yml
```

---

## ğŸ› ï¸ Tech Stack

### Frontend

- React / Next.js
- TailwindCSS
- Axios

### Backend

- FastAPI
- Python
- OpenAI Whisper
- OpenAI GPT / Llama / Ollama (configurable)

### Infrastructure (AWS)

- **EC2** â€“ Backend hosting
- **S3** â€“ Audio files, manuals
- **RDS PostgreSQL** â€“ Database
- **IAM** â€“ Permissions
- **Route 53 (optional)** â€“ Custom domain

### Additional

- Pinecone (vector DB)
- LangChain (optional orchestration)
- PDF/Markdown manual creator

---

## ğŸ§ª API Endpoints

### **POST /transcribe**

Upload an audio file â†’ returns transcript

### **POST /troubleshoot**

Send transcript â†’ returns steps + manual

---

## ğŸ“¦ Installation (Local)

### Backend

```
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Frontend

```
cd frontend
npm install
npm run dev
```

API will run at:

---

## â˜ï¸ Deployment (AWS Summary)

**Backend options:**

**Storage:**

- S3 bucket for audio + manuals

**Database:**

- RDS PostgreSQL or Supabase

**Vector Search:**

- Pinecone cloud

---

## ğŸ“Œ Status

The backend RAG pipeline, ingestion, and testing are functional.  
Next steps include:

- Hook frontend â†’ backend API
- Deploy FastAPI on AWS
- Deploy frontend on Vercel or AWS Amplify
- Add PDF/manual generation to UI

---

## ğŸ§‘â€ğŸ’» Contributors

- Isaiah Cruz
- Michal Dzienski
- Geovens Jean B.
- Emmanuel McCrimmon
- Dylan Stechmann

---

## ğŸ“„ License

MIT License.
